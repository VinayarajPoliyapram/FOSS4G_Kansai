{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ準備\n",
    "## ソースデータセット\n",
    "ISPRS Vaihingen Datasetは、ISPRSの委員会IIIによって提供されます。データセットは9 cmの空間解像度で構成されています\n",
    "赤と緑のバンドが付いた航空写真。データセットには、約0.6 km2をカバーする16のラベル付きシーンが含まれます。\n",
    "ラベルは6つのクラスに提供されます：不浸透性の表面、建物、低植生、木、車、クラッター/バックグラウンド。通常、ラベルの量が非常に限られているため、クラッター/バックグラウンドクラスは無視されます。\n",
    "## データを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset/isprs_vaihingen/train/label/', '../dataset/isprs_vaihingen/train/label_rgb/', '../dataset/isprs_vaihingen/train/image/']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob('../dataset/isprs_vaihingen/train/*/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset/isprs_vaihingen/val/label/', '../dataset/isprs_vaihingen/val/label_rgb/', '../dataset/isprs_vaihingen/val/image/']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob('../dataset/isprs_vaihingen/val/*/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset/isprs_vaihingen/test/label/', '../dataset/isprs_vaihingen/test/label_rgb/', '../dataset/isprs_vaihingen/test/image/']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob('../dataset/isprs_vaihingen/test/*/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニング画像とラベルを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PILを使用してイメージをndarrayとして読み取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(Image.open('../dataset/isprs_vaihingen/train/image/top_mosaic_09cm_area21.tif'))\n",
    "label = np.array(Image.open('../dataset/isprs_vaihingen/train/label_rgb/top_mosaic_09cm_area21.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ignore annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(image, interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Image')\n",
    "fig.show()\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(label, interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Label')\n",
    "\n",
    "fig.suptitle('Scene: top_mosaic_09cm_area1')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスラベルは次のとおりです。 <br>\n",
    "0: 不浸透性の表面 (white)<br>\n",
    "1: 建物 (blue)<br>\n",
    "2: 低植生 (cyan)<br>\n",
    "3: 樹木 (green)<br>\n",
    "4: 車 (yellow)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理\n",
    "## 前処理\n",
    "ディープラーニングメソッドを適用するには、次のように前処理を行う必要があります。\n",
    "* 切り抜き\n",
    "* 正規化\n",
    "\n",
    "## 切り抜き\n",
    "これで、トレーニング画像（area1）のサイズは $1919\\times2569$ です。ご存知のように、リモートセンシング画像のサイズは非常に大きいことが一般的です。 1つの問題は、このような大きな画像にディープラーニングメソッドを直接適用できないことです。これは、メソッドが通常メモリを消費するためです。多くの場合、1つのモデルでサイズが $256\\times256$のパッチを処理するために数GBのRAMメモリが必要です。ディープラーニングをリモートセンシング画像に適用するには、大きな画像から小さなパッチを切り抜く必要があります。ここでは、その方法を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "### 単一のパッチをランダムに切り取る\n",
     "以下では、トレーニング画像とラベルから、サイズが $256\\times256$ のトレーニングパッチをランダムに切り取ります。最初に、元の大きな画像からの単一パッチのトリミングを示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "トレーニングイメージと対応するラベルのファイルパスを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_train_image1 = '../dataset/isprs_vaihingen/train/image/top_mosaic_09cm_area21.tif'\n",
    "fpath_train_image2 = '../dataset/isprs_vaihingen/train/image/top_mosaic_09cm_area7.tif'\n",
    "fpath_train_label1 = '../dataset/isprs_vaihingen/train/label/top_mosaic_09cm_area21.tif'\n",
    "fpath_train_label2 = '../dataset/isprs_vaihingen/train/label/top_mosaic_09cm_area7.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "インポートモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "トレーニング画像とラベルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = np.array(Image.open(fpath_train_image1))\n",
    "image2 = np.array(Image.open(fpath_train_image2))\n",
    "label1 = np.array(Image.open(fpath_train_label1))\n",
    "label2 = np.array(Image.open(fpath_train_label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "画像とラベルのペアをリストに配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = [\n",
    "    ['top_mosaic_09cm_area21', image1, label1],\n",
    "    ['top_mosaic_09cm_area7' , image2, label2],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングシーンのリストからターゲットシーンをランダムに選択する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, image, label = random.choice(list_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "トリミング位置をランダムに選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, _ = image.shape\n",
    "patch_size = 256\n",
    "ulx = random.randrange(0, width - patch_size + 1)\n",
    "uly = random.randrange(0, height - patch_size + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "パッチペアをトリミングする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_patch = image[uly:uly+patch_size, ulx:ulx+patch_size, :]\n",
    "label_patch = label[uly:uly+patch_size, ulx:ulx+patch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "ここで、サイズが $256\\times256$ のパッチペアをトリミングしました。パッチを表示して、パッチが正しくトリミングされているかどうかを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(image_patch, interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.show()\n",
    "ax.set_title('Image patch')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(label_patch, interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Label patch')\n",
    "\n",
    "fig.suptitle('Scene: %s at (%d,%d)-(%d,%d)' % (name, ulx, uly, ulx+patch_size, uly+patch_size))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "ニューラルネットワークは、入力として左側の画像パッチを受け取り、対応する分類結果を出力します。\n",
     "トレーニングの目標は、ネットワークの出力が右側の真のラベルに近づくように、ネットワークパラメータを最適化することです。\n",
     "目に見えない画像に一般化するネットワークをトレーニングするには、ネットワークがさまざまなパターンを学習できるように、さまざまなそのようなトレーニングパッチペアが必要です。そのため、以下では、トレーニングシーンから複数のパッチをトリミングします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "### 複数のパッチをランダムに切り取る\n",
     " 上記のように、ここではトレーニングシーンから複数のパッチをトリミングします。基本的に、上記と同じ手順を繰り返し適用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トリミングの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = 750\n",
    "patch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "トリミングされたパッチを含めるためのプレースホルダーを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image_patches = []\n",
    "list_label_patches = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "定義された数のパッチが収集されるまで、ランダムクロッピングを繰り返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_patches):\n",
    "    # choose scenes randomly\n",
    "    name, image, label = random.choice(list_data)\n",
    "\n",
    "    # choose crop position randomly\n",
    "    height, width, _ = image.shape\n",
    "    ulx = random.randrange(0, width - patch_size + 1)\n",
    "    uly = random.randrange(0, height - patch_size + 1)\n",
    "\n",
    "    # crop\n",
    "    image_patch = image[uly:uly+patch_size, ulx:ulx+patch_size, :]\n",
    "    label_patch = label[uly:uly+patch_size, ulx:ulx+patch_size]\n",
    "\n",
    "    # contain\n",
    "    list_image_patches.append(image_patch)\n",
    "    list_label_patches.append(label_patch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "プレースホルダーをndarrayに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_image_patches = np.array(list_image_patches)\n",
    "npy_label_patches = np.array(list_label_patches)\n",
    "\n",
    "print(npy_image_patches.shape)\n",
    "print(npy_label_patches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "トリミングされたパッチペアを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "grid = GridSpec(nrows=2, ncols=10)\n",
    "\n",
    "fig = plt.figure(figsize=(20,4))\n",
    "\n",
    "for i in range(10):\n",
    "    idx = random.randrange(len(npy_image_patches))\n",
    "    image_patch = npy_image_patches[idx]\n",
    "    label_patch = npy_label_patches[idx]\n",
    "    \n",
    "    ax = fig.add_subplot(grid[0,i])\n",
    "    ax.imshow(image_patch, interpolation='none')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title('ID:%d' % idx)\n",
    "\n",
    "    ax = fig.add_subplot(grid[1,i])\n",
    "    ax.imshow(label_patch, interpolation='none')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "最後に、後で再利用できるように、トリミングコードを関数として実装します。<br><br>\n",
     "**入力**: \n",
     "- シーンのリスト(name, image, label)\n",
     "- 切り取るパッチの数\n",
     "- パッチのサイズs\n",
     "\n",
     "**出力**: \n",
     "- トリミングされた画像パッチ (ndarray)\n",
     "- クロップドラベルパッチ (ndarray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(list_data, num_patches, patch_size):\n",
    "    list_image_patches = []\n",
    "    list_label_patches = []\n",
    "\n",
    "    for i in range(num_patches):\n",
    "        # choose scenes randomly\n",
    "        name, image, label = random.choice(list_data)\n",
    "\n",
    "        # choose crop position randomly\n",
    "        height, width, _ = image.shape\n",
    "        ulx = random.randrange(0, width - patch_size + 1)\n",
    "        uly = random.randrange(0, height - patch_size + 1)\n",
    "\n",
    "        # crop\n",
    "        image_patch = image[uly:uly+patch_size, ulx:ulx+patch_size, :]\n",
    "        label_patch = label[uly:uly+patch_size, ulx:ulx+patch_size]\n",
    "\n",
    "        # contain\n",
    "        list_image_patches.append(image_patch)\n",
    "        list_label_patches.append(label_patch)\n",
    "    \n",
    "    npy_image_patches =  np.array(list_image_patches)\n",
    "    npy_label_patches =  np.array(list_label_patches)\n",
    "\n",
    "    return npy_image_patches, npy_label_patches\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "## 正規化\n",
     "必要な別の前処理は、トリミングされたパッチの正規化です。通常、ニューラルネットワークの入力画像は正規化されます。シンプルだが広く使用されている方法は、範囲調整です。メソッドは、ピクセル値の範囲を\\[0,1\\]または\\[-1,1\\]に調整します。たとえば、8ビットのイメージがある場合、各ピクセル値を255で除算すると、\\[0,1\\]の範囲のピクセル値になります。地上ベースの画像の場合、これらの方法は広く使用されています。ただし、リモートセンシング画像の場合、各バンドを正規化して平均と単位の分散をゼロにすることをお勧めします。\n",
     "\n",
     "### なぜ正規化が必要なのでしょう？\n",
     "主に2つの理由があります。\n",
     "1. **高速なトレーニングと良好な収束のため。** ニューラルネットワークパラメーターの初期化は、正規化された入力を前提としています。したがって、正規化を行わないと、初期パラメーター値は最適とはほど遠いものになり、トレーニング時間が長くなるか、さらに悪いことにトレーニングが収束しなくなります。 \n",
     "2. **堅牢性のため。** 取得条件（照明条件やセンサーなど）の影響を正規化するため。\n",
     "\n",
     "以下では、正規化について説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "帯域ごとの平均と標準偏差を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = np.mean(image1, axis=(0,1), keepdims=True)\n",
    "mean2 = np.mean(image2, axis=(0,1), keepdims=True)\n",
    "std1 = np.std(image1, axis=(0,1), keepdims=True)\n",
    "std2 = np.std(image2, axis=(0,1), keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "元の画像を正規化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_normalized = (image1 - mean1) / std1\n",
    "image2_normalized = (image2 - mean2) / std2\n",
    "\n",
    "list_data_normalized = [\n",
    "    ['top_mosaic_09cm_area21', image1_normalized, label1],\n",
    "    ['top_mosaic_09cm_area7' , image2_normalized, label2],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "正規化された画像を使用したランダムクロップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_image_patches, npy_label_patches = random_crop(list_data_normalized, num_patches=750, patch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "これで、トレーニングデータの前処理が完了しました。最後に、トリミングしたパッチをnumpyファイルとして保存しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set output directory for cropped patches\n",
    "import os\n",
    "output_dir_train = '../dataset/isprs_vaihingen/train/patches/'\n",
    "if not os.path.isdir(output_dir_train):\n",
    "    os.mkdir(output_dir_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "パッチをnumpyファイルとして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(output_dir_train + '/image.npy', npy_image_patches)\n",
    "np.save(output_dir_train + '/label.npy', npy_label_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "### 前処理検証パッチ\n",
     "トレーニングパッチと同じ方法で検証パッチを前処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file path\n",
    "fpath_val_image = '../dataset/isprs_vaihingen/val/image/top_mosaic_09cm_area11.tif'\n",
    "fpath_val_label = '../dataset/isprs_vaihingen/val/label/top_mosaic_09cm_area11.tif'\n",
    "\n",
    "# pre-load images and labels\n",
    "image = np.array(Image.open(fpath_val_image))\n",
    "label = np.array(Image.open(fpath_val_label))\n",
    "\n",
    "# normalize\n",
    "mean = np.mean(image1, axis=(0,1), keepdims=True)\n",
    "std = np.std(image1, axis=(0,1), keepdims=True)\n",
    "image_normalized = (image - mean) / std\n",
    "\n",
    "# to list\n",
    "list_data_normalized = [\n",
    "    ['top_mosaic_09cm_area11', image_normalized, label],\n",
    "]\n",
    "\n",
    "# cropping\n",
    "npy_image_patches, npy_label_patches = random_crop(list_data_normalized, num_patches=100, patch_size=256)\n",
    "\n",
    "# save\n",
    "output_dir_val = '../dataset/isprs_vaihingen/val/patches/'\n",
    "if not os.path.isdir(output_dir_val):\n",
    "    os.mkdir(output_dir_val)\n",
    "np.save(output_dir_val + '/image.npy', npy_image_patches)\n",
    "np.save(output_dir_val + '/label.npy', npy_label_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "### 予測のためのテストパッチの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "テストパッチはランダムに作成されません。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "fpath_test_image = '../dataset/isprs_vaihingen/test/image/top_mosaic_09cm_area30.tif'\n",
    "fpath_test_label = '../dataset/isprs_vaihingen/test/label/top_mosaic_09cm_area30.tif'\n",
    "image = np.array(Image.open(fpath_test_image))\n",
    "label = np.array(Image.open(fpath_test_label))\n",
    "\n",
    "# Normalize\n",
    "mean = np.mean(image, axis=(0,1), keepdims=True)\n",
    "std = np.std(image, axis=(0,1), keepdims=True)\n",
    "image = (image - mean) / std\n",
    "\n",
    "patch_size = 256\n",
    "stride = 256\n",
    "height, width, _ = image.shape\n",
    "\n",
    "num_tiles_x = (width - patch_size) // stride + 1\n",
    "num_tiles_y = (height - patch_size) // stride + 1\n",
    "\n",
    "list_image_patches = []\n",
    "list_label_patches = []\n",
    "for iy in range(num_tiles_y):\n",
    "    for ix in range(num_tiles_x):\n",
    "        ulx = ix * stride\n",
    "        uly = iy * stride\n",
    "        lrx = ulx + patch_size\n",
    "        lry = uly + patch_size\n",
    "            \n",
    "        image_patch = image[uly:lry, ulx:lrx, :]\n",
    "        label_patch = label[uly:lry, ulx:lrx]\n",
    "        \n",
    "        list_image_patches.append(image_patch)\n",
    "        list_label_patches.append(label_patch)\n",
    "\n",
    "npy_image_patches = np.array(list_image_patches)\n",
    "npy_label_patches = np.array(list_label_patches)\n",
    "\n",
    "# save\n",
    "output_dir_test = '../dataset/isprs_vaihingen/test/patches/'\n",
    "if not os.path.isdir(output_dir_test):\n",
    "    os.mkdir(output_dir_test)\n",
    "np.save(output_dir_test + '/image.npy', npy_image_patches)\n",
    "np.save(output_dir_test + '/label.npy', npy_label_patches)\n",
    "\n",
    "print(npy_image_patches.shape)\n",
    "print(npy_label_patches.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
